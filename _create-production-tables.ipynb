{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf2ae44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cday\\Anaconda3\\lib\\site-packages\\geopandas\\_compat.py:124: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- SETUP ---\n",
    "# conda install -c conda-forge google-cloud-bigquery\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52de05bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import global TDM functions\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../Resources/2-Python/global-functions\")\n",
    "import BigQuery\n",
    "\n",
    "client = BigQuery.getBigQueryClient_Confidential2023UtahHTS()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645ff9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connected to BigQuery project: wfrc-modeling-data\n",
      "Target dataset: prd_tdm_hts_2023\n",
      "SQL directory: \n",
      "\n",
      "▶ Running: day.sql  →  wfrc-modeling-data.prd_tdm_hts_2023.day\n",
      "✔ Done: wfrc-modeling-data.prd_tdm_hts_2023.day\n",
      "\n",
      "▶ Running: hh.sql  →  wfrc-modeling-data.prd_tdm_hts_2023.hh\n",
      "✔ Done: wfrc-modeling-data.prd_tdm_hts_2023.hh\n",
      "\n",
      "▶ Running: person.sql  →  wfrc-modeling-data.prd_tdm_hts_2023.person\n",
      "✔ Done: wfrc-modeling-data.prd_tdm_hts_2023.person\n",
      "\n",
      "▶ Running: trip_unlinked.sql  →  wfrc-modeling-data.prd_tdm_hts_2023.trip_unlinked\n",
      "✔ Done: wfrc-modeling-data.prd_tdm_hts_2023.trip_unlinked\n",
      "\n",
      "▶ Running: trip_linked.sql  →  wfrc-modeling-data.prd_tdm_hts_2023.trip_linked\n",
      "✔ Done: wfrc-modeling-data.prd_tdm_hts_2023.trip_linked\n",
      "\n",
      "▶ Running: vehicle.sql  →  wfrc-modeling-data.prd_tdm_hts_2023.vehicle\n",
      "✔ Done: wfrc-modeling-data.prd_tdm_hts_2023.vehicle\n",
      "\n",
      "✅ All SQL scripts completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIG ---\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\", \"wfrc-modeling-data\")\n",
    "BQ_LOCATION = os.getenv(\"BQ_LOCATION\", \"US\")\n",
    "TARGET_DATASET = os.getenv(\"TARGET_DATASET\", \"prd_tdm_hts_2023\")\n",
    "\n",
    "# Optional prefix/suffix for table names\n",
    "TABLE_PREFIX = os.getenv(\"TABLE_PREFIX\", \"\")  # e.g., \"build_20251007_\"\n",
    "TABLE_SUFFIX = os.getenv(\"TABLE_SUFFIX\", \"\")  # e.g., \"_v2\"\n",
    "\n",
    "# Ordered list of SQL files to execute\n",
    "ORDERED_SQL_FILES = [\n",
    "    \"day.sql\",\n",
    "    \"hh.sql\",\n",
    "    \"person.sql\",\n",
    "    \"trip_unlinked.sql\",\n",
    "    \"trip_linked.sql\",\n",
    "    \"vehicle.sql\",\n",
    "]\n",
    "\n",
    "# Path to your SQL directory\n",
    "SQL_DIR = \"\"  # adjust this path if needed\n",
    "\n",
    "print(f\"✅ Connected to BigQuery project: {PROJECT_ID}\")\n",
    "print(f\"Target dataset: {TARGET_DATASET}\")\n",
    "print(f\"SQL directory: {SQL_DIR}\")\n",
    "\n",
    "\n",
    "# --- RUNNER FUNCTION ---\n",
    "def run_sql_file(sql_file: str):\n",
    "    \"\"\"Run a SQL file and write results to BigQuery table.\"\"\"\n",
    "    base_name = os.path.splitext(sql_file)[0]\n",
    "    table_name = f\"{TABLE_PREFIX}{base_name}{TABLE_SUFFIX}\"\n",
    "    table_id = f\"{PROJECT_ID}.{TARGET_DATASET}.{table_name}\"\n",
    "\n",
    "    print(f\"\\n▶ Running: {sql_file}  →  {table_id}\")\n",
    "\n",
    "    # Load SQL from file\n",
    "    with open(os.path.join(SQL_DIR, sql_file), \"r\", encoding=\"utf-8\") as f:\n",
    "        sql = f.read()\n",
    "\n",
    "    # Define job config\n",
    "    job_config = bigquery.QueryJobConfig(\n",
    "        destination=table_id,\n",
    "        write_disposition=\"WRITE_TRUNCATE\",  # replace if exists\n",
    "    )\n",
    "\n",
    "    # Execute query\n",
    "    query_job = client.query(sql, job_config=job_config)\n",
    "    query_job.result()  # Wait for job to complete\n",
    "\n",
    "    print(f\"✔ Done: {table_id}\")\n",
    "\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "for file in ORDERED_SQL_FILES:\n",
    "    file_path = os.path.join(SQL_DIR, file)\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Missing file: {file_path}\")\n",
    "    run_sql_file(file)\n",
    "\n",
    "print(\"\\n✅ All SQL scripts completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
